{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/sub-files'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\n\n","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs = '/kaggle/input/sub-files/'\nsvm_subs = pd.read_csv(subs+'svm_subs.csv')\nsvm_sub1 = pd.read_csv('/kaggle/input/svm-sub1/SVM_sub1')\nlasso_subs = pd.read_csv(subs+'lasso_subs.csv')\nenet_subs = pd.read_csv(subs+'enet_preds.csv')\nridge_subs = pd.read_csv(subs+'ridge_subs.csv')\nsvm_df = pd.read_csv('/kaggle/input/svmdomain2preds/SVM_df.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making svm preds from svm_df because svm subs somehow wasnt scoring well\nsvm_cols = ['pred' +'_'+ str(target) for target in targets]\nsvm_df = svm_df.drop(domains, axis=1)\nsvm_df = svm_df.rename(columns= {'pred_age':'age', 'pred_domain1_var1':'domain1_var1', 'pred_domain1_var2':'domain1_var2', 'pred_domain2_var1':'domain2_var1', 'pred_domain2_var2':'domain2_var2'})\nsvm_preds = svm_df[domains]\nsvm_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Data Loader\n###Metric\n###Feature options\n\nroot = '/kaggle/input/trends-assessment-prediction/'\nfnc_df = pd.read_csv('/kaggle/input/trends-assessment-prediction/fnc.csv')\nloading_df = pd.read_csv(root+'loading.csv')\nreveal = pd.read_csv(root+'reveal_ID_site2.csv')\nnumbers = pd.read_csv(root+'ICN_numbers.csv')\nsample_sub = pd.read_csv(root+'sample_submission.csv')\nlabels_df = pd.read_csv(root+'train_scores.csv')\n\ndf=pd.DataFrame()\nfnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_df.columns[1:])\n\ndf = fnc_df.merge(loading_df, on=\"Id\")\n\nlabels_df['is_train'] = True\n\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\n\n\ntest_df = df[df[\"is_train\"] != True].copy()\ndf = df[df[\"is_train\"] == True].copy()\n\n#metric scorer\ndef metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))\n\nsvm_loss_dict={'age': '0.1445',\n 'domain1_var1': '0.1512',\n 'domain1_var2': '0.1512',\n 'domain2_var1': '0.1818',\n 'domain2_var2': '0.1761'}\n\nselected0 = ['IC_01', 'IC_02', 'IC_04', 'IC_06', 'IC_08', 'IC_09', 'IC_10',\n       'IC_12', 'IC_15', 'IC_21', 'IC_22', 'IC_26']\n\nselected1 = ['IC_01', 'IC_02', 'IC_04', 'IC_06', 'IC_08', 'IC_09', 'IC_10',\n       'IC_12', 'IC_15', 'IC_21', 'IC_22', 'IC_26',\n 'IC_17','IC_07','IC_11', 'IC_16' ]\n\nselected2 =  ['IC_01', 'IC_02', 'IC_03', 'IC_04', 'IC_06', 'IC_07', 'IC_08',\n       'IC_09', 'IC_10', 'IC_11', 'IC_12', 'IC_13', 'IC_14', 'IC_15',\n       'IC_16', 'IC_17', 'IC_18', 'IC_21', 'IC_22', 'IC_24', 'IC_26',\n       'IC_28', 'IC_29']\n\ndomains = [\"age\",\"domain1_var1\",\"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]\n\n\n\n\"\"\"WARNING\"\"\"\n# ここはいじくり回してるので実行前に必ず見ること\ndf[fnc_features]*= 1.0/600.0\ntest_df[fnc_features]*= 1.0/600.0\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subs = [svm_subs, lasso_subs, ridge_subs, enet_subs]\nsub_names = ['svm_subs', 'lasso_subs', 'ridge_subs', 'enet_subs']\n\nsubs_name_dict = {}\nfor i in range(4):\n    subs_name_dict.update({sub_names[i]:subs[i].columns.values.tolist()})\n    \nsubs_dict = {}\nfor i in range(4):\n    subs_dict.update({sub_names[i]:subs[i]})\n    \n    \n    \n\nfinal_sub = pd.DataFrame()\nfor target in domains:\n    sub_mean = pd.Series()\n    for sub_name in sub_names:\n        if target in subs_name_dict[sub_name]:\n            sub_mean = pd.concat([subs_dict[sub_name][target], sub_mean], axis=1)\n        else:\n            pass\n        sub_mean.dropna(axis=1)\n        final_sub[target] = sub_mean.mean(axis=1)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# fig, axes = plt.subplots(nrows=2, ncols = 3)\n# target = domains[0]\nfor target in domains:\n    legends = []\n    plt.figure(figsize=(8, 4))\n    for sub_name in sub_names:\n        if target in subs_name_dict[sub_name]:\n            g = sns.distplot(subs_dict[sub_name][target])#label=sub_name)\n            legends.append(sub_name)\n        else:\n            pass\n    sns.distplot(df[target])\n    g.legend(legends)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sklearn.gaussian_process.GaussianProcessRegressor(kernel=None, *, alpha=1e-10, optimizer='fmin_l_bfgs_b', n_restarts_optimizer=0, normalize_y=False, copy_X_train=True, random_state=None)[source]¶\n\n\n\n\n\ndef cv_und_sub(train, test, model, alpha, targets, features, folds=5):\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = loading_features + fnc_features","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RIDGE REGRESSION\nfrom sklearn.linear_model import Ridge\n\nfeatures = loading_features + fnc_features\n\ntest = test_df\ntrain = df\n\ntargets = domains\n\nfolds = 5\nkf = KFold(n_splits = folds)\nalphas = [1e-4, 4e-4, 5e-4, 0.001]\n\nalpha_preds = pd.DataFrame()\nalpha_losses = pd.DataFrame()\n\nfor alpha in alphas:\n    model = Ridge(alpha=alpha)\n    \n################## if putting in a function, do it from here #################################\n    \n    target_preds = pd.DataFrame()\n    print('ALPHA : ', alpha, '\\n')\n    \n    alpha_loss = []\n    for target in targets:\n        cv_preds =pd.DataFrame(np.zeros((test.shape[0], folds)))\n        cv_loss = 0\n        train = train.loc[train[target].notnull()]\n        for fold, (train_ind, val_ind) in enumerate(kf.split(train)):\n            X_train, X_val = train.iloc[train_ind][features], train.iloc[val_ind][features]\n            y_train, y_val =  train.iloc[train_ind][target], train.iloc[val_ind][target]\n\n            model.fit(X_train, y_train)\n            train_pred = model.predict(X_val)\n\n            cv_loss += metric(y_val, train_pred)/folds\n\n            test_pred = model.predict(test[features])\n\n            cv_preds.loc[:, fold] = test_pred\n        \n        \n        mean = cv_preds.mean(axis=1)\n        \n        target_preds[target] = mean\n        alpha_preds[f'{alpha}_'+target] = mean\n            \n        alpha_loss.append(cv_loss)\n        \n        alpha_losses.loc[target, f'{alpha}'] = cv_loss \n        print('TARGET : ', target)\n        print('LOSS                         : ', cv_loss)\n    print('\\nOVERALL                      : ', alpha_loss[0]*0.3+alpha_loss[1]*0.175+alpha_loss[2]*0.175+alpha_loss[3]*0.175+alpha_loss[4]*0.175)\n    print('\\n\\n')\n    \n\n\n  \n\n\n\n\n##dict for getting series out of alpha preds\n\nalpha_preds_cols = {}\nfor alpha in alphas:\n    cols = [(str(alpha) +'_'+ str(target)) for target in targets]\n    alpha_preds_cols.update({str(alpha):cols})\n    \nridge_preds1 = alpha_preds[alpha_preds_cols['0.001']]\nridge_preds2 = alpha_preds[alpha_preds_cols['0.0004']]","execution_count":4,"outputs":[{"output_type":"stream","text":"ALPHA :  0.0001 \n\nTARGET :  age\nLOSS                         :  0.1432812156066702\nTARGET :  domain1_var1\nLOSS                         :  0.15516233029617718\nTARGET :  domain1_var2\nLOSS                         :  0.15575583016641764\nTARGET :  domain2_var1\nLOSS                         :  0.18650575752862425\nTARGET :  domain2_var2\nLOSS                         :  0.1818970635658823\n\nOVERALL                      :  0.16186553645449378\n\n\n\nALPHA :  0.0004 \n\nTARGET :  age\nLOSS                         :  0.1451468178267745\nTARGET :  domain1_var1\nLOSS                         :  0.15243533414224938\nTARGET :  domain1_var2\nLOSS                         :  0.15272730313427835\nTARGET :  domain2_var1\nLOSS                         :  0.182483831599851\nTARGET :  domain2_var2\nLOSS                         :  0.17782417046044294\n\nOVERALL                      :  0.16000140723197614\n\n\n\nALPHA :  0.0005 \n\nTARGET :  age\nLOSS                         :  0.14544947931917246\nTARGET :  domain1_var1\nLOSS                         :  0.15215949664473766\nTARGET :  domain1_var2\nLOSS                         :  0.15240073236565904\nTARGET :  domain2_var1\nLOSS                         :  0.18209891980168935\nTARGET :  domain2_var2\nLOSS                         :  0.17739459022207832\n\nOVERALL                      :  0.15984424812673048\n\n\n\nALPHA :  0.001 \n\nTARGET :  age\nLOSS                         :  0.1467254186369068\nTARGET :  domain1_var1\nLOSS                         :  0.15156679108215887\nTARGET :  domain1_var2\nLOSS                         :  0.15162582220845736\nTARGET :  domain2_var1\nLOSS                         :  0.1813504037782967\nTARGET :  domain2_var2\nLOSS                         :  0.17649131735304271\n\nOVERALL                      :  0.15969863411491425\n\n\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# plotting predictions\nfor target in domains:\n#     g = sns.distplot(alpha_preds[alpha_preds_cols['0.001']]['0.001'+'_'+target])\n#     g = sns.distplot(alpha_preds[alpha_preds_cols['0.0004']]['0.0004'+'_'+target])\n    g= sns.distplot(svm_subs[target])\n    g= sns.distplot(svm_preds[target])\n    g.legend(['ridge', 'ridge2', 'svm'])\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding weights\n# svm_weight_dict ={'age':0.45, 'domain1_var1':0.55,'domain1_var2':0.7, 'domain2_var1':0.7,  'domain2_var2':0.4}\n# ridge1_weight_dict = {'age':0.55, 'domain1_var1':0.45,'domain1_var2':0.3, 'domain2_var1':0.3,  'domain2_var2':0.6}#alpha = 0.001\n\n\nsvm_weight_dict ={'age':0.5, 'domain1_var1':0.5,'domain1_var2':0.5, 'domain2_var1':0.5,  'domain2_var2':0.5}\nridge1_weight_dict = {'age':0.5, 'domain1_var1':0.5,'domain1_var2':0.5, 'domain2_var1':0.5,  'domain2_var2':0.5}\n\n\n# ridge2_weight_dict = {'age':0.0, 'domain1_var1':0.0,'domain1_var2':0.0, 'domain2_var1':0.0,  'domain2_var2':0.0}#alpha = 0.0004\n\n#renaming ridge_preds\nridge_preds1.rename(columns = {'0.001_age':'age', '0.001_domain1_var1':'domain1_var1','0.001_domain1_var2':'domain1_var2',\n                              '0.001_domain2_var1':'domain2_var1', '0.001_domain2_var2':'domain2_var2'}, inplace=True)\nridge_preds2.rename(columns = {'0.0004_age':'age', '0.0004_domain1_var1':'domain1_var1','0.0004_domain1_var2':'domain1_var2',\n                              '0.0004_domain2_var1':'domain2_var1', '0.0004_domain2_var2':'domain2_var2'}, inplace=True)\n\npred_df = pd.DataFrame()\nfor target in domains:\n    pred_df[target] = svm_weight_dict[target]*svm_1[target] + ridge1_weight_dict[target]*ridge_preds1[target]\n                        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_sub(pred_df):\n    sub_df = pd.melt(pred_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=['Id'], value_name='Predicted')\n\n    sub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\n    sub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\n\n    #assert here is for debugging\n    assert sub_df.shape[0] == test_df.shape[0]*5\n\n    return sub_df\n\n#change here for the final step\npred_df = final_sub\n\ntest_df.reset_index(drop=True, inplace=True)\npred_df.reset_index(drop=True, inplace=True)\npred_df['Id'] = test_df['Id'].astype('int')\nsub_df = to_sub(pred_df)\nsub_df.to_csv('sub.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['Id'] = sub_df['Id']\nsub['Predicted'] = (svm_sub1['Predicted']+sub_df['Predicted'])/2.0\nsub.to_csv('sub.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_sub1 = pd.read_csv('/kaggle/input/svm-sub1/SVM_sub1')\n\nfor i in range(svm_sub1.shape[0]):\n    svm_sub1['Id'].iloc[i] =  svm_sub1['Id'].iloc[i].replace(svm_sub1['Id'].iloc[i][:6], '')\n    \nsvm_sub1 = svm_sub1.pivot(columns = 'Id')\n\nsvm_sub1.columns = svm_sub1.columns.droplevel(0)\n\nsvm_dict = {}\n\nfor target in domains:\n    svm_dict.update({target:svm_sub1.loc[svm_sub1[target].notnull()][target].reset_index()})\n\nsvm_1 = pd.DataFrame()\nfor target in domains:\n    svm_1[target] = svm_dict[target][target]\n    \nsvm_1.to_csv('svm_preds1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dict for getting series out of alpha preds\n\nalpha_preds_cols = {}\nfor alpha in alphas:\n    cols = [(str(alpha) +'_'+ str(target)) for target in targets]\n    alpha_preds_cols.update({str(alpha):cols})\n    \n    \n\ndef plot_per_alpha(alpha):\n    sub_df = alpha_preds[alpha_preds_cols[str(alpha)]]\n\n    for target in targets:\n        alpha_col = f'{alpha}'+'_'+target\n        plt.figure(figsize=(5, 2), dpi=100)\n        sns.distplot(sub_df[alpha_col])\n        sns.distplot(train[target])\n        plt.legend(['sub_df', 'train'] )\n        plt.show()\n        \nplot_per_alpha(0.0005)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GPR\n\n\ntest = test_df\ntrain = df\n\ntargets = domains\n\nfolds = 5\nkf = KFold(n_splits = folds)\n\n\nalpha_preds = pd.DataFrame()\nalpha_losses = pd.DataFrame()\n\n\n\nfrom sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\nkernel = DotProduct() + WhiteKernel()\nmodel = GPR(kernel=kernel)\nalpha = 1e-5\ntarget_preds = pd.DataFrame()\n\nfor target in targets:\n    cv_preds =pd.DataFrame(np.zeros((test.shape[0], folds)))\n    cv_loss = 0\n    train = train.loc[train[target].notnull()]\n    for fold, (train_ind, val_ind) in enumerate(kf.split(train)):\n        X_train, X_val = train.iloc[train_ind][features], train.iloc[val_ind][features]\n        y_train, y_val =  train.iloc[train_ind][target], train.iloc[val_ind][target]\n\n        model.fit(X_train, y_train)\n        train_pred = model.predict(X_val)\n\n        cv_loss += metric(y_val, train_pred)/folds\n\n        test_pred = model.predict(test[features])\n\n        cv_preds.loc[:, fold] = test_pred\n\n\n    mean = cv_preds.mean(axis=1)\n\n    target_preds[target] = mean\n    alpha_preds[f'{alpha}_'+target] = mean\n\n    alpha_losses.loc[target, f'{alpha}'] = cv_loss \n    print('TARGET : ', target)\n    print('LOSS                         : ', cv_loss)\nprint('\\n\\n')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}